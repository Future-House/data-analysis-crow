{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLATFORM ROLLOUT\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from futurehouse_client import FutureHouseClient\n",
    "from futurehouse_client.models import Stage, TaskRequest, RuntimeConfig\n",
    "from futurehouse_client.models.app import AuthType\n",
    "import fhda.prompts as prompts\n",
    "from ldp.agent import AgentConfig\n",
    "\n",
    "# CONFIGURATION\n",
    "CROW_STAGE = Stage.PROD  # Don't change this\n",
    "API_KEY = \"\"  # Add your API key here\n",
    "JOB_NAME = \"job-futurehouse-data-analysis-crow-high\"  # Don't change this\n",
    "MAX_STEPS = 30  # You can change this to impose a limit on the number of steps\n",
    "LANGUAGE = \"R\"  # Choose between \"R\" and \"PYTHON\"\n",
    "DATA_GCS_LOCATION = \"eda/flow0\"  # This is the location of the dataset on GCS â€“ ask someone from FutureHouse to upload new datasets\n",
    "MODEL_NAME = \"claude-3-7-sonnet-latest\"  # Feel free to use any Litellm supported model\n",
    "TEMPERATURE = 1.0  # Feel free to try different model temperatures\n",
    "\n",
    "# Here is where you can update the prompt. As shown below, by default we use CoT prompting,\n",
    "# but it is not necessary and we encourage users to experiment with different prompting strategies.\n",
    "query = \"\"\"\n",
    "Make a discovery using this dataset\n",
    "\"\"\"\n",
    "\n",
    "task = f\"\"\"\\\n",
    "Here is the user query to address:\n",
    "\n",
    "<query>\n",
    "{query}\n",
    "</query>\n",
    "{prompts.CHAIN_OF_THOUGHT_AGNOSTIC.format(language=LANGUAGE)}\n",
    "{prompts.GENERAL_NOTEBOOK_GUIDELINES.format(language=LANGUAGE)}\"\"\"\n",
    "\n",
    "# This is extra R prompting to avoid long R output blocks\n",
    "if LANGUAGE == \"R\":\n",
    "    task += f\"\\n{prompts.R_OUTPUT_RECOMMENDATION_PROMPT}\"\n",
    "\n",
    "\n",
    "# You shouldn't have to change anything below here\n",
    "client = FutureHouseClient(\n",
    "    stage=CROW_STAGE,\n",
    "    auth_type=AuthType.API_KEY,\n",
    "    api_key=API_KEY,\n",
    ")\n",
    "\n",
    "job_data = TaskRequest(\n",
    "    name=JOB_NAME,\n",
    "    query=task,\n",
    "    runtime_config=RuntimeConfig(\n",
    "        max_steps=MAX_STEPS,\n",
    "        upload_id=DATA_GCS_LOCATION,  # This is just an example dataset\n",
    "        environment_config={\n",
    "            \"run_notebook_on_edit\": False,\n",
    "            \"eval\": True,  # DO NOT CHANGE THIS\n",
    "            \"language\": LANGUAGE,\n",
    "        },\n",
    "        agent=AgentConfig(\n",
    "            agent_type=\"ReActAgent\",\n",
    "            agent_kwargs={\n",
    "                \"llm_model\": {\"name\": MODEL_NAME, \"temperature\": TEMPERATURE},\n",
    "            },\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "job_id = client.create_task(job_data)\n",
    "status = \"in progress\"\n",
    "while status in [\"in progress\", \"queued\"]:\n",
    "    print(\"Waiting for task to complete... checking again in 30 seconds\")\n",
    "    time.sleep(15)\n",
    "    status = client.get_task(job_id).status\n",
    "\n",
    "if status == \"failed\":\n",
    "    raise Exception(\"Task failed\")\n",
    "\n",
    "job_result = client.get_task(job_id, verbose=True)\n",
    "answer = job_result.environment_frame[\"state\"][\"state\"][\"answer\"]\n",
    "print(\n",
    "    f\"Task completed, the full analysis is available at:https://platform.futurehouse.org/trajectories/{job_id}\\n Agent answer: {answer}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also view the notebook locally by saving it to a directory of your choice\n",
    "# Define the path where you want to save the notebook\n",
    "notebook_path = \"output/analysis_notebook.ipynb\"\n",
    "\n",
    "os.makedirs(os.path.dirname(notebook_path), exist_ok=True)\n",
    "notebook_content = job_result.environment_frame[\"state\"][\"state\"][\"nb_state\"]\n",
    "with open(notebook_path, \"w\") as f:\n",
    "    json.dump(notebook_content, f, indent=2)\n",
    "\n",
    "print(f\"Notebook saved to {os.path.abspath(notebook_path)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
