{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from futurehouse_client import FutureHouseClient\n",
    "from futurehouse_client.models import TaskRequest, RuntimeConfig\n",
    "from futurehouse_client.models.app import AuthType\n",
    "import fhda.prompts as prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the FutureHouse client with your API key\n",
    "FH_API_KEY = \"\"  # Add your API key here\n",
    "JOB_NAME = \"job-futurehouse-data-analysis-crow-high\"  # Don't change this\n",
    "UPLOAD_ID = (\n",
    "    \"finch_tutorial\"  # This is the folder name of the dataset you uploaded to GCS\n",
    ")\n",
    "\n",
    "client = FutureHouseClient(\n",
    "    auth_type=AuthType.API_KEY,\n",
    "    api_key=FH_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset – note you only have to do this once\n",
    "client.upload_file(JOB_NAME, file_path=\"dataset\", upload_id=UPLOAD_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what files were uploaded to your gcs folder\n",
    "client.list_files(JOB_NAME, upload_id=UPLOAD_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your task\n",
    "# Here is where you can update the prompt. As shown below, by default we use CoT prompting,\n",
    "# but it is not necessary and we encourage users to experiment with different prompting strategies.\n",
    "LANGUAGE = \"PYTHON\"  # Choose between \"R\" and \"PYTHON\"\n",
    "MAX_STEPS = 30  # You can change this to impose a limit on the number of steps the agent can take\n",
    "query = \"Make a short notebook with visualizations exploring the dataset.\"\n",
    "\n",
    "task = (\n",
    "    f\"{prompts.CHAIN_OF_THOUGHT_AGNOSTIC.format(language=LANGUAGE)}\\n\"\n",
    "    f\"{prompts.GENERAL_NOTEBOOK_GUIDELINES.format(language=LANGUAGE)}\"\n",
    "    f\"Here is the research question to address:\\n\"\n",
    "    f\"<query>\\n\"\n",
    "    f\"{query}\\n\"\n",
    "    f\"</query>\\n\"\n",
    ")\n",
    "\n",
    "# This is extra R prompting to avoid long R output blocks – also feel free to discard this\n",
    "if LANGUAGE == \"R\":\n",
    "    task += f\"\\n{prompts.R_OUTPUT_RECOMMENDATION_PROMPT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how to create a task – you shouldn't need to change anything here\n",
    "job_data = TaskRequest(\n",
    "    name=JOB_NAME,\n",
    "    query=task,\n",
    "    runtime_config=RuntimeConfig(\n",
    "        max_steps=MAX_STEPS,\n",
    "        upload_id=UPLOAD_ID,\n",
    "        environment_config={\n",
    "            \"eval\": True,  # DO NOT CHANGE THIS\n",
    "            \"language\": LANGUAGE,\n",
    "        },\n",
    "    ),\n",
    ")\n",
    "trajectory_id = client.create_task(job_data)\n",
    "print(\n",
    "    f\"Task running on platform, you can view progress live at:https://platform.futurehouse.org/trajectories/{trajectory_id}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jobs take on average 3-10 minutes to complete\n",
    "status = \"in progress\"\n",
    "while status in [\"in progress\", \"queued\"]:\n",
    "    time.sleep(15)\n",
    "    status = client.get_task(trajectory_id).status\n",
    "\n",
    "if status == \"failed\":\n",
    "    raise Exception(\"Task failed\")\n",
    "\n",
    "job_result = client.get_task(trajectory_id, verbose=True)\n",
    "answer = job_result.environment_frame[\"state\"][\"state\"][\"answer\"]\n",
    "print(f\"The agent's answer to your research question is: \\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In addition to viewing the notebook and reasoning trace via the platform,\n",
    "# you can also list the files in the trajectory directory and download any files you need\n",
    "print(client.list_files(JOB_NAME, trajectory_id=trajectory_id))\n",
    "\n",
    "destination_path = \"output/notebook.ipynb\"\n",
    "file_path = \"notebook.ipynb\"\n",
    "client.download_file(\n",
    "    JOB_NAME,\n",
    "    trajectory_id=trajectory_id,\n",
    "    file_path=file_path,\n",
    "    destination_path=destination_path,\n",
    ")\n",
    "print(f\"Notebook saved to {os.path.abspath(destination_path)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
