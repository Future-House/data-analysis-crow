{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-agent consensus tutorial\n",
    "\n",
    "In this tutorial, we will be using two different agents, Finch and Crow to do differential expression analysis on some RNASeq data from [here](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE52778). Additionally, we do consensus sampling with Finch to improve reliability of the results.\n",
    "\n",
    "The process follows four steps:\n",
    "1. Differential expression analysis: run 10 DEAs in parallel with Finch\n",
    "2. Consensus sampling: Aggregate the results of the DEAs with Finch\n",
    "3. Literature search: Use Crow to search the literature for the top differentially expressed genes\n",
    "4. Visualization: Use Finch to create a final interactive volcano plot containing all differentially expressed genes, their evidence and the evidence score.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "from futurehouse_client import FutureHouseClient, JobNames\n",
    "from futurehouse_client.models import TaskRequest, RuntimeConfig\n",
    "from futurehouse_client.models.app import AuthType\n",
    "import fhda.prompts as prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the prompts we'll be using\n",
    "TREATMENT = \"dexamethasone\"\n",
    "MECHANISM = \"airway smooth muscle cells\"\n",
    "CONTEXT = \"asthma\"\n",
    "N_TOP_GENES = 10\n",
    "DEA_PROMPT = \"\"\"\n",
    "Determine the effect of {treatment} on {mechanism} in {context}. \n",
    "\n",
    "Perform differential expression analysis and pathway analysis on relevant comparison groups. Map all gene IDs to gene symbols using annotation package such as ‘org.Hs.eg.db’.\n",
    "\n",
    "Generate volcano plots and heatmap of differentially expressed genes, and dot plots for enriched pathways, use gene symbols for labels where relevant.\n",
    "\n",
    "Output a single csv file named \"dea_results.csv\"  with the results for all tested genes of the most relevant contrast, report both gene ID and gene symbol.\n",
    "\n",
    "If there is an error, keep trying, do not give up until you reach the end of the analysis. When mapping gene ID to gene symbol, consider all possible forms of gene IDs, keep trying until the gene symbols are obtained.\n",
    "\"\"\"\n",
    "\n",
    "CONSENSUS_PROMPT = f\"\"\"\n",
    "Combine these differential expression analysis results by calculating the mode of log2FC and adjusted p values. Output the results in a file named ‘consensus_results.csv’, include the columns gene_symbol, log2FC and adjusted P values. In a separate file named ‘top_genes.csv’, output the top {N_TOP_GENES} gene symbols of the consensus most significant genes with the column name “gene_symbol”. \n",
    "\n",
    "Create a stacked bar plot showing gene regulation consistency across all analyses. Plot regulation direction (up vs down) on x-axis and percentage of genes in each category on y-axis. Color-code by significance category: all analyses, >50% of analyses and  <50% of analyses. Include percentages within each segment and a clear legend. Exclude genes that are non-significant across all analyses.\n",
    "\"\"\"\n",
    "\n",
    "PQA_PROMPT = \"\"\"\n",
    "    What are the possible mechanisms for {gene} in the effect of {treatment} on {mechanism} in {context}?\n",
    "    From 1 to 5, with 1 being no evidence of association at all and 5 being strong association with supporting evidence, how strong is the evidence supporting this mechanism?\n",
    "    Give a concise summary for the evidence in up to 10 words, and a short summary of mechanisms in up to 20 words. Do not include references or links.\n",
    "    Please share this information in json format in the form of: `\"gene_symbol\": <gene_symbol>, \"association_evidence_score\":[1...5], \"evidence_summary\": <evidence_summary>, \"mechanism_summary\": <mechanism_summary>`.\n",
    "    Share nothing else but the JSON output.\n",
    "    \"\"\"\n",
    "\n",
    "VOLCANO_PROMPT = \"\"\"\n",
    "Make an interactive volcano plot. Colour-code by significance categories: top up-regulated genes, up-regulated genes, top down-regulated genes, down-regulated genes, and non-significant genes. Genes considered as top differentially expressed genes have extra annotation available in 'pqa_results.csv’.\n",
    "\n",
    "Include hover information according to the categories, for the top genes, on hover, show gene symbol, log2FC, adjusted p value, mechanism, evidence and evidence score. For up and down regulated genes that are not in top differentially expressed genes, show gene symbol, log2FC and adjusted p value. For non-significant genes, do not include hover information.\n",
    "\n",
    "For the annotations, remove all text in the brackets in the summary columns, and remove the fullstop at the end. For annotations with 6 words or more in a line, use text-wrap. Don’t include text on the plot itself. Include a legend explaining the color-codes.\n",
    "\n",
    "PLEASE USE TEXT WRAP FOR THE HOVER INFORMATION!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def augment_query(query, language):\n",
    "    guidelines = prompts.GENERAL_NOTEBOOK_GUIDELINES.format(language=language)\n",
    "    if language == \"R\":\n",
    "        guidelines = prompts.R_SPECIFIC_GUIDELINES.format(language=language)\n",
    "    return (\n",
    "        f\"{prompts.CHAIN_OF_THOUGHT_AGNOSTIC.format(language=language)}\\n\"\n",
    "        f\"{guidelines}\"\n",
    "        f\"Here is the research question to address:\\n\"\n",
    "        f\"<query>\\n\"\n",
    "        f\"{query}\\n\"\n",
    "        f\"</query>\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we instantiate the FutureHouse client and define the job names\n",
    "FH_API_KEY = \"\"  # Add your API key here\n",
    "# We will be creating three folders in GCS to store the results of the three steps\n",
    "DEA_UPLOAD_ID = f\"consensus_tutorial_dea_{str(uuid.uuid4())[:8]}\"\n",
    "CONSENSUS_UPLOAD_ID = f\"consensus_tutorial_consensus_{str(uuid.uuid4())[:8]}\"\n",
    "PQA_UPLOAD_ID = f\"consensus_tutorial_pqa_{str(uuid.uuid4())[:8]}\"\n",
    "INITIAL_RNASEQ_FILE = \"datasets/GSE52778_All_Sample_FPKM_Matrix.txt.gz\"\n",
    "client = FutureHouseClient(\n",
    "    auth_type=AuthType.API_KEY,\n",
    "    api_key=FH_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's upload the dataset to GCS and check the files were uploaded correctly\n",
    "client.upload_file(\n",
    "    JobNames.FINCH, file_path=INITIAL_RNASEQ_FILE, upload_id=DEA_UPLOAD_ID\n",
    ")\n",
    "# Check what files were uploaded to your gcs folder\n",
    "client.list_files(JobNames.FINCH, upload_id=DEA_UPLOAD_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's run 5 Finch DEA tasks in parallel\n",
    "NUM_DEA_TASKS = 5\n",
    "TIMEOUT = 15 * 60\n",
    "runtime_config = RuntimeConfig(\n",
    "    max_steps=30,\n",
    "    upload_id=DEA_UPLOAD_ID,\n",
    "    environment_config={\n",
    "        \"default_cot_prompt\": False,\n",
    "        \"language\": \"R\",\n",
    "    },\n",
    ")\n",
    "task_request = TaskRequest(\n",
    "    name=JobNames.FINCH,\n",
    "    query=augment_query(\n",
    "        DEA_PROMPT.format(treatment=TREATMENT, mechanism=MECHANISM, context=CONTEXT),\n",
    "        \"R\",\n",
    "    ),\n",
    "    runtime_config=runtime_config,\n",
    ")\n",
    "dea_completed_tasks = await client.arun_tasks_until_done(\n",
    "    [task_request for i in range(NUM_DEA_TASKS)], progress_bar=True, timeout=TIMEOUT\n",
    ")\n",
    "dea_task_ids = [str(task.task_id) for task in dea_completed_tasks]\n",
    "success = sum([task.status == \"success\" for task in dea_completed_tasks])\n",
    "print(f\"Task success rate: {success / NUM_DEA_TASKS * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Finch runs should take anywhere between 3-10 minutes to complete.\n",
    "# Once the runs have completed, lets's download the results upload them to a new folder in GCS and run a consensus step\n",
    "for c, task_id in enumerate(dea_task_ids):\n",
    "    try:\n",
    "        client.download_file(\n",
    "            JobNames.FINCH,\n",
    "            trajectory_id=task_id,\n",
    "            file_path=\"dea_results.csv\",\n",
    "            destination_path=f\"output/dea_results/dea_results_{c}.csv\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading task results for task {task_id}: {e}\")\n",
    "\n",
    "# Now let's upload the whole directory of consensus results to GCS\n",
    "client.upload_file(\n",
    "    JobNames.FINCH, file_path=\"output/dea_results\", upload_id=CONSENSUS_UPLOAD_ID\n",
    ")\n",
    "\n",
    "print(\"These files have been uploaded to GCS:\")\n",
    "print(client.list_files(JobNames.FINCH, upload_id=CONSENSUS_UPLOAD_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets's run a single consensus step\n",
    "runtime_config = RuntimeConfig(\n",
    "    max_steps=30,\n",
    "    upload_id=CONSENSUS_UPLOAD_ID,\n",
    "    environment_config={\n",
    "        \"default_cot_prompt\": False,\n",
    "        \"language\": \"R\",\n",
    "    },\n",
    ")\n",
    "consensus_task_request = TaskRequest(\n",
    "    name=JobNames.FINCH,\n",
    "    query=augment_query(CONSENSUS_PROMPT, \"R\"),\n",
    "    runtime_config=runtime_config,\n",
    ")\n",
    "consensus_task_response = client.run_tasks_until_done(\n",
    "    [consensus_task_request], progress_bar=True, timeout=TIMEOUT\n",
    ")\n",
    "consensus_task_id = consensus_task_response[0].task_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the consensus step is done, lets's download the results\n",
    "client.download_file(\n",
    "    JobNames.FINCH,\n",
    "    trajectory_id=consensus_task_id,\n",
    "    file_path=\"consensus_results.csv\",\n",
    "    destination_path=\"output/consensus_results.csv\",\n",
    ")\n",
    "client.download_file(\n",
    "    JobNames.FINCH,\n",
    "    trajectory_id=consensus_task_id,\n",
    "    file_path=\"top_genes.csv\",\n",
    "    destination_path=\"output/top_genes.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use PaperQA to give us a summary of each gene\n",
    "top_genes_df = pd.read_csv(\"output/top_genes.csv\")\n",
    "display(top_genes_df.head())\n",
    "gene_symbols = top_genes_df[\"gene_symbol\"].tolist()\n",
    "pqa_tasks = [\n",
    "    {\n",
    "        \"name\": JobNames.CROW,\n",
    "        \"query\": PQA_PROMPT.format(\n",
    "            gene=gene, treatment=TREATMENT, mechanism=MECHANISM, context=CONTEXT\n",
    "        ),\n",
    "    }\n",
    "    for gene in gene_symbols\n",
    "]\n",
    "pqa_task_list = await client.arun_tasks_until_done(\n",
    "    pqa_tasks, progress_bar=True, timeout=TIMEOUT, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when PQAs are done, parse answers to csv\n",
    "\n",
    "answer_list = []\n",
    "for task_response in pqa_task_list:\n",
    "    try:\n",
    "        answer = json.loads(\n",
    "            task_response.environment_frame[\"state\"][\"state\"][\"response\"][\"answer\"][\n",
    "                \"answer\"\n",
    "            ]\n",
    "        )\n",
    "        if isinstance(answer, list):\n",
    "            answer = answer[0]\n",
    "        answer_list.append(answer)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing answer for task {task_response.task_id}: {e}\")\n",
    "\n",
    "pqa_df = pd.DataFrame(answer_list)\n",
    "pqa_df.to_csv(\"output/pqa_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally let's create a beutiful interactive plotly plot that brings all the results together\n",
    "# Now lets's run a single consensus step\n",
    "client.upload_file(\n",
    "    JobNames.FINCH, file_path=\"output/pqa_results.csv\", upload_id=PQA_UPLOAD_ID\n",
    ")\n",
    "client.upload_file(\n",
    "    JobNames.FINCH, file_path=\"output/consensus_results.csv\", upload_id=PQA_UPLOAD_ID\n",
    ")\n",
    "runtime_config = RuntimeConfig(\n",
    "    max_steps=30,\n",
    "    upload_id=PQA_UPLOAD_ID,\n",
    "    environment_config={\n",
    "        \"default_cot_prompt\": False,\n",
    "        \"language\": \"PYTHON\",\n",
    "    },\n",
    ")\n",
    "volcano_task_request = TaskRequest(\n",
    "    name=JobNames.FINCH,\n",
    "    query=augment_query(VOLCANO_PROMPT, \"PYTHON\"),\n",
    "    runtime_config=runtime_config,\n",
    ")\n",
    "volcano_task_id = client.create_task(volcano_task_request)\n",
    "\n",
    "print(\n",
    "    f\"Task running on platform, you can view progress live for our final results at:https://platform.futurehouse.org/trajectories/{volcano_task_id}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final trajectory will have the reliable results of our DEA analysis in an interactive volcano plotly plot containing the top differentially expressed genes, their evidence and the evidence score! All in about 20 minutes!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
